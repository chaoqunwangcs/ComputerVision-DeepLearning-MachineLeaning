# 1. 有监督学习模型
**决策树、线性模型（LDA）、贝叶斯、KNN、集成学习** \
**决策树**是一种基于规则的方法，它用一组嵌套的规则进行预测，在树的每个决策节点处，根据判断结果进入一个分支，反复执行这种操作直到到达叶子节点，得到决策结果，它的规则是通过训练样本学习得到的，决策树是一种判别模型，也是非线性模型，天然支持多类分类问题。它既可以用于分类问题，也可以用于回归问题，具有很好的解释性，符合人类的思维习惯。常用的决策树有 ID3，C4.5，分类与回归树（CART）等。分类树对应的映射函数是多维空间的分段线性划分，即用平行于各个坐标轴的超平面对空间进行切分；回归树的映射函数是一个分段常数函数。决策树是分段线性函数但不是线性函数，它具有非线性建模的能力。只要划分的足够细，分段常数函数可以逼近闭区间上任意函数到任意指定精度，因此决策树在理论上可以对任意复杂度的数据进行分类或者回归。
**线性模型**的预测函数是线性函数，既可以用于分类问题，也可以用于回归问题，这是机器学习算法中的一个庞大家族。从线性模型中衍生出了多种机器学习算法，对于分类问题，有岭回归，LASSO 回归；对于分类问题，有支持向量机，logistic 回归，softmax 回归，人工神经网络（多层感知器模型），以及后续的各种深度神经网络。
# 1.1 决策树   
决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法  
## ID3 
由增熵（Entropy）原理来决定那个做父节点，那个节点需要分裂。对于一组数据，熵越小说明分类结果越好。熵定义如下：  
$$Entropy = -\sum p_{x_i}*log_{2}p_{x_i}$$  
对于样本的多个属性，选择熵最小的属性（分类效果最好的属性）作为父节点，构建决策树  
## C4.5  
通过对ID3的学习，可以知道ID3存在一个问题，那就是越细小的分割分类错误率越小，所以ID3会越分越细,但是这种分割显然只对训练数据有用，对于新的数据没有意义，这就是所说的过度学习（Overfitting)。
分割太细了，训练数据的分类可以达到0错误率，但是因为新的数据和训练数据不同，所以面对新的数据分错率反倒上升了。决策树是通过分析训练数据，得到数据的统计信息，而不是专为训练数据量身定做。
为了避免分割太细，c4.5对ID3进行了改进，C4.5中，优化项要除以分割太细的代价，这个比值叫做信息增益率，显然分割太细分母增加，信息增益率会降低。除此之外，其他的原理和ID3相同。
$$Info(D)=-\sum p_{x_i}log_2p_{x_i}--(ID3)$$
$$Info_{A}=\sum_{j=1}^v \frac{|D_j|}{|D|} \times Info(D_j)$$
$$gain(A)=Info(D)-Info_{A}(D)$$
$$SplitInfo_{A}(D)=-\sum_{j=1}^v \frac{|D_j|}{|D|} \times log_{2}(\frac {|D_j|}{|D|})$$
$$GainRatio(A)=\frac{Gain(A)}{SplitInfo(A)} --C4.5$$
## CART(Classification And Regression Tree)
ID3中使用了信息增益选择特征，增益大优先选择。C4.5中，采用信息增益比选择特征，减少因特征值多导致信息增益大的问题。CART分类树算法使用基尼系数来代替信息增益比，基尼系数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（比）相反。
假设K个类别，第k个类别的概率为pk，概率分布的基尼系数表达式：
$$Gini(p)=\sum_{k=1}^K p_k(1-p_k) = 1 - \sum_{k=1}^K p_k^2$$
对于样本D，个数为|D|，假设K个类别，第k个类别的数量为|Ck|，则样本D的基尼系数表达式：
$$Gini(D)=1-\sum_{k=1}^K (\frac{|C_k|}{|D|})^2$$
对于样本D，个数为|D|，根据特征A的某个值a，把D分成|D1|和|D2|，则在特征A的条件下，样本D的基尼系数表达式为：
$$Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)$$
CART分类树算法每次仅对某个特征的值进行二分，而不是多分，这样CART分类树算法建立起来的是二叉树，而不是多叉树。
**CART回归树**和CART分类树的建立类似，这里只说不同:
1. 分类树与回归树的区别在样本的输出，如果样本输出是离散值，这是分类树；样本输出是连续值，这是回归树。分类树的输出是样本的类别，回归树的输出是一个实数。
2. 连续值的处理方法不同.
3. 决策树建立后做预测的方式不同。

|算法|支持模型|树结构|特征选择|连续值处理|缺失值处理|剪枝|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|ID3|分类|多叉树|信息增益|不支持|不支持|不支持|
|C4.5|分类|多叉树|信息增益比|支持|支持|支持|
|CART|分类回归|二叉树|基尼指数、均方差|支持|支持|支持|

## 剪枝
在决策树的创建时，由于数据中的噪声和离群点，许多分枝反映的是训练数据中的异常。剪枝方法是用来处理这种过分拟合数据的问题。通常剪枝方法都是使用统计度量，剪去最不可靠的分枝。
剪枝一般分两种方法：先剪枝和后剪枝。
**先剪枝**方法中通过提前停止树的构造（比如决定在某个节点不再分裂或划分训练元组的子集）而对树剪枝。一旦停止，这个节点就变成树叶，该树叶可能取它持有的子集最频繁的类作为自己的类。
另一种更常用的方法是**后剪枝**，它由完全成长的树剪去子树而形成。通过删除节点的分枝并用树叶来替换它。树叶一般用子树中最频繁的类别来标记。

## 决策树小结
### 优点
1. 简单直观，生成的决策树很直观。
2. 基本不需要预处理，不需要提前归一化和处理缺失值。
3. 使用决策树预测的代价是O(log2m)。m为样本数。
4. 既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。
5. 可以处理多维度输出的分类问题。
6. 相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以很好解释。
7. 可以交叉验证的剪枝来选择模型，从而提高泛化能力。
8. 对于异常点的容错能力好，健壮性高。
### 缺点
1. 决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。
2. 决策树会因为样本发生一点的改动，导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。 
3. 寻找最优的决策树是一个NP难题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习的方法来改善。
4. 有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。
5. 如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。

# 1.2 线性模型
线性模型的预测函数是线性函数，既可以用于分类问题，也可以用于回归问题，这是机器学习算法中的一个庞大家族。从线性模型中衍生出了多种机器学习算法，对于回归问题，有**岭回归**，***LASSO* 回归**；对于分类问题，有**支持向量机（SVM）**，***logistic* 回归**，***softmax* 回归**，**人工神经网络（多层感知器模型）**，以及后续的各种**深度神经网络**。
对于分类问题，线性模型的预测函数为:
$$f(x)=sgn(w^Tx+b)$$
其中 sgn 是符号函数。最简单的线性分类器是感知器算法.
对于回归问题，线性模型的预测函数为：
$$f(x)=w^Tx+b$$
训练时的目标是最小化均方误差：
$$\min_{w} \frac{1}{2} \sum_{i=1}^{l}(w^Tx_i-y_i)^2$$
可以证明，这是一个凸优化问题，可以得到全局极小值。求解时可以采用梯度下降法或者牛顿法。
## 1.2.1 岭回归
岭回归是线性回归的 L2 正则化版本，训练时求解的问题为:
$$\min_{w} \frac{1}{2} \sum_{i=1}^{l}(w^Tx_i-y_i)^2 + \lambda w_2^2$$
如果系数 l > 0 ，这个问题是一个严格凸优化问题，可用用梯度下降法，牛顿法求解，该公式有[闭式解](https://blog.csdn.net/Joker_sir5/article/details/82756089)。
## 1.2.2 LASSO回归
LASSO回归和岭回归类似，不同的是，Lasso可以理解为在线性回归基础上加入一个L1正则项，同样来限制W不要过大。其中λ>0，通过确定λ的值可以使得模型在偏差和方差之间达到平衡，随着λ的增大，模型的方差减小，偏差增大。
[L1,L2正则化区别](https://blog.csdn.net/wwyy2018/article/details/99765142)
L1 优化和L2优化，都可以通过约束参数空间降低模型过拟合的风险，**奥卡姆剃刀原理**

## 1.2.3 线性判别分析LDA 

[传送门](https://www.cnblogs.com/pinard/p/6244265.html) 
LDA是一种有监督的线性投影技术，它寻找向低维空间的投影矩阵 W，样本的特征向量 x 经过投影之后得到的新向量 y：
$$y=Wx$$
投影的目标是同一类样投影后的结果向量同类**样本差异尽可能小，不同类的样本差异尽可能大**。直观来看，就是经过这个投影之后同一类的样本进来聚集在一起，不同类的样本尽可能离得远。对于**二分类问题**：

$$\arg \min_{w} J(w)=\frac{||w^T\mu_0 - w^T\mu_1||_2^2}{w^T\sum_0w+w^T\sum_1w} = \frac{w^T(\mu_0-\mu_1)(\mu_0-\mu_1)^Tw}{w^T(\sum_0+\sum_1)w}$$

定义类内散度矩阵：

$$S_w=\sum_0+\sum_1=\sum_{x \in X_0}(x-\mu_0)(x-\mu_0)^T +\sum_{x \in X_1}(x-\mu_1)(x-\mu_1)^T$$

定义类间散度矩阵：

$$S_b=(\mu_0-\mu_1)(\mu_0-\mu_1)^T$$

于是，优化目标转化为：

$$\arg \min_{w} J(w) = \frac{w^TS_bw}{w^TS_ww}$$

可以求得：

$$w=S_w^{-1}(\mu_0-\mu_1)$$

**LDA&&PCA**
均为降维方法，相同点：
1. 两者均可以对数据进行降维。
2. 两者在降维时均使用了矩阵特征分解的思想。
3. 两者都假设数据符合高斯分布。
不同点：
1. LDA是有监督的降维方法，而PCA是无监督的降维方法
2. LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。
3. LDA除了可以用于降维，还可以用于分类。
4. LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。

**LDA小结**
LDA算法既可以用来降维，又可以用来分类，但是目前来说，主要还是用于降维。在我们进行图像识别图像识别相关的数据分析时，LDA是一个有力的工具。

优点:
1. 在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。
2. LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。

缺点：
1. LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。
2. LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。
3. LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。
4. LDA可能过度拟合数据。

## 1.2.4 支持向量机（SVM）

[传送门](https://zhuanlan.zhihu.com/p/31886934)
支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。

SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示， $wx+b=0$ 即为分离超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。
定义训练集
$$T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}$$
$x_i \in R^n, y_i \in {+1, -1}, i = 1,2,...N$。 假设样本点$(x_i,y_i)$和超平面$wx+b=0$的集合间隔为：
$$\gamma_i = y_i(\frac{w}{||w||}\cdot x_i + \frac{b}{||w||})$$
于是SVM可以表示为以下约束最优化问题：
$$\max_{w,b} \gamma $$
$$s.t. y_i(\frac{w}{||w||}\cdot x_i + \frac{b}{||w||}) >= \gamma, i=1,2,...,N$$
向量机的一个重要性质：训练完成后，大部分的训练样本都不需要保留，最终模型仅与支持向量有关。

## 1.2.5 logistic 回归

[传送门](https://zhuanlan.zhihu.com/p/95132284)

logistic 回归又叫对数几率回归，适合数值型的二值型输出的拟合，它其实是一个分类模型，比如根据患者的医疗数据判断它是否能被治愈.
我们考虑1个输入的$n$维数据$x=(x_1,x_2,...,x_n)$，我们对输入数据进行线性加权得到：
$$g(x)=w_0+w_1x_1+...+w_nx_n$$
前面说到，logistic回归用于而分类，假设得到的类别为0或者1，那么可以**使用sigmoid函数处理输入**，这个函数类似于阶跃函数但是又是连续型函数
sigmoid(x)其实衡量的是输入数据 $x$ 归属于类别 1 的概率，当$x<0$ 的时候，$sigmoid(x)<0.5$可以认为 $x$ 归属于类别 0 的概率较大，当$x>0$的时候，$sigmoid(x)>0.5$可以任务$x$归属为类别1的概率较大。如果我们将线性加权得到的$g(x)$作为 sigmoid 函数的输入，得到
$$f(x)=\frac{1}{1+e^{-g(x)}}=\sigma(f(x))=\sigma(w^Tx)$$
这样就得到了输入数据 $x$ 最终属于类别 1 的概率,我们先考虑使用常规的均方差作为损失函数，这时候的损失函数为
$$L(w) = \frac{1}{2} (y-f(x))^2 = \frac{1}{2} (y-\sigma(w^Tx))^2$$
随后可以利用梯度下降法进行优化。


**Logistic回归和线性回归区别**
1. Logistic回归在线性回归的实数输出范围加上sigmoid函数，将输出值收敛在0~1之间。其目标函数也因此从差平方和函数变为对数损失函数。

2. 逻辑回归和线性回归都是广义的线性回归，线性回归是使用最小二乘法优化目标函数，而逻辑回归是使用梯度下降或者拟牛顿法。

3. 线性回归在整个实数域范围内进行预测，敏感度一致，而分类范围需要在[0,1]。逻辑回归是一种减少预测范围，将预测值限定为[0,1]间的一种回归模型。因而对于二分类问题，逻辑回归的鲁棒性更好。

4. 逻辑回归是以线性回归为理论支持的，但线性回归模型无法做到sigmoid的非线性形式。Sigmoid可以轻松处理0/1分类问题。

**为什么Logistic回归的输入特征一般都是离散化而不是连续的？**

1. 离散特征容易增加和减少，使得模型容易迭代。

2. 离散特征的内积运算速度快，计算结果方便存储。

3. 对异常值不敏感，比如一个特征是年龄>30为1，否则为0，如果特征没有离散化。一个异常数据300岁会给模型带来很大的干扰。

4. 逻辑回归是广义线性模型，表达能力受限。单变量离散化为N个后，每个变量都有单独的权重，相当于为模型引入了非线性，能够提升模型的表达能力，加大拟合。

5. 特征离散化后可以进行特征交叉，由M+N变量变为M*N个变量，进一步引入非线性，提升表达能力。

6. 特征离散化后，模型会更加稳定。比如对用户年龄离散化，将20~30作为一个区间，这样不会因为一个用户年龄大了一岁就变成完全不同的人了，当然处于区间相邻处的样本就刚好相反，所以怎么划分区间是们学问。

7. 特征离散化后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

**Logistic回归和SVM的关系**
1. LR和SVM都可以处理分类问题，且一般都处理线性二分类问题。

2. LR是参数模型，SVM是非参数模型。

3. LR的目标函数是对数似然函数，SVM的目标函数是hinge损失函数。这两个函数都是增加对分类结果影响较大的数据点的权重，减少影响较小的数据点的权重。

4. SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。

5. 逻辑回归相对来说模型更简单，好理解，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些，SVM转化为对偶问题后,分类只需要计算与少数几个支持向量的距离,这个在进行复杂核函数计算时优势很明显,能够大大简化模型和计算。

6. logic能做的svm能做，但可能在准确率上有问题，svm能做的logic有的做不了。


## 1.2.6 softmax 回归
[传送门](https://zhuanlan.zhihu.com/p/98061179)
softmax 回归(softmax regression)其实是 logistic 回归的一般形式，logistic 回归用于二分类，而 softmax 回归用于多分类，
对于输入数据${(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}$有k个类别，即$y_i \in {1,2,...,k}$，那么softmax回归主要估算输入数据$x_i$归属每个类别的概率，即：
$$h_\theta(x_i) = [p(y_i=1|x_i;\theta),p(y_i=2|x_i;\theta),...,p(y_i=k|x_i;\theta)]^T$$
$$h_\theta (x_i) = \frac{1}{\sum_{j=1}^{k} e^{\theta _j^{T}x_i}} \cdot [e^{\theta _1^{T}x_i},e^{\theta _2^{T}x_i},...,e^{\theta _k^{T}x_i}]$$
其中，$\theta_1,\theta_2,...,\theta_k \in \theta$是模型参数，乘以$\frac{1}{\sum_{j=1}^{k} e^{\theta _j^{T}x_i}}$是为了归一化，softmax回归将输入数据$x_i$归为$j$类的概率为：
$$p(y_i=j|x_i;\theta) = \frac{e^{\theta _j^{T}x_i}}{\sum_{j=1}^{k}e^{\theta _j^{T}x_i}}$$
之后，可以利用梯度下降法求参，具体见[传送门](https://zhuanlan.zhihu.com/p/98061179)

# 1.3 KNN
[传送门](https://zhuanlan.zhihu.com/p/31758206)

Cover 和 Hart 在 1968 年提出了最初的邻近算法，用于解决分类( classification )的问题。KNN是一种基于实例学习( instance-based learning )，或者所是将所有计算推迟到分类之后的惰性学习( lazy learning )的一种算法，KNN是所有机器学习算法中最简单算法之一。

**KNN算法的思路是: 如果一个样本在特征空间中的 k 个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。通常 K 的取值比较小，不会超过 20。**
**算法步骤为：**
1. 计算未知实例到所有已知实例的距离；
2. 选择参数 K；
3. 根据多数表决( majority-voting )规则，将未知实例归类为样本中最多数的类别。

距离： 欧氏距离 $d(x,y)=\sqrt{\sum_{i=1}^{n}(x_i-y_i)^2}$，曼哈顿距离:$d(x,y)=\sum_{i=0}^{n}|x_i-y_i|$
**KNN优缺点：**
优点:
1. 简单，易于理解，无需建模与训练，易于实现；
2. 适合对稀有事件进行分类；
3. 适合与多分类问题，例如根据基因特征来判断其功能分类，kNN比SVM的表现要好。

缺点：
1. 惰性算法，内存开销大，对测试样本分类时计算量大，性能较低；
2. 可解释性差，无法给出决策树那样的规则。

# 1.4 贝叶斯
[传送门](https://zhuanlan.zhihu.com/p/42991859)

# 1.5 集成学习
[传送门](https://zhuanlan.zhihu.com/p/55811589)
集成学习是机器学习中一个非常重要且热门的分支，是**用多个弱分类器构成一个强分类器**，其哲学思想是“三个臭皮匠赛过诸葛亮”。一般的弱分类器可以由决策树，神经网络，贝叶斯分类器，K-近邻等构成。已经有学者理论上证明了集成学习的思想是可以提高分类器的性能的，比如说统计上的原因，计算机上的原因以及表示上的原因。
## 为什么用集成学习？
1. 模型选择
假设各弱分类器间具有一定的差异性（如不同的算法，或相同算法不同参数配置），这会导致生成的分类决策边界不同，也就是说它们在决策时会犯不同的错误。将它们结合后能得到更合理的边界，减少整体错误，实现更好的分类效果。
2. 数据集过大或过小
数据集较大时，可以分为不同的子集，分别进行训练，然后再合成分类器。
数据集较小时，可以用自举技术(bootstrapping),从原样本集有放回的抽取m个子集，训练m个分类器，进行集成.
3. 分治
若决策边界过于复杂，则线性模型不能很好地描述真实情况。因此先训练多个线性分类器，再将它们集成。
4. 数据融合(Data Fusion)
当有多个不同数据源，且每个数据源的特征集抽取方法都不同时（异构的特征集），需要分别训练分类器然后再集成。

## 常用算法：boosting, Bagging, Stacking
**boosting**的弱分类器形成是同一种机器学习算法，只是其数据抽取时的权值在不断更新，每次都是提高前一次分错了的数据集的权值，最后得到T个弱分类器，且分类器的权值也跟其中间结果的数据有关。
**Bagging**算法也是用的同一种弱分类器，其数据的来源是用bootstrap算法得到的（有放回抽样，一个instance被前面分错的越厉害，它的概率就被设的越高）。
**Stacking**算法分为两个阶段，首先我们使用多个基础分类器来预测分类；然后，一个新的学习模块与它们的预测结果结合起来，来降低泛化误差。

## 1.5.1 Boosting

**Boosting**是一种框架算法,主要是通过对样本集的操作获得样本子集,然后用弱分类算法在样本子集上训练生成一系列的基分类器。他可以用来提高其他弱分类算法的识别率,也就是将其他的弱分类算法作为基分类算法放于Boosting 框架中,通过Boosting框架对训练样本集的操作,得到不同的训练样本子集,用该样本子集去训练生成基分类器;每得到一个样本集就用该基分类算法在该样本集上产生一个基分类器,这样在给定训练轮数 n 后,就可产生 n 个基分类器,然后Boosting框架算法将这 n个基分类器进行加权融合,产生一个最后的结果分类器,在这 n个基分类器中,每个单个的分类器的识别率不一定很高,但他们联合后的结果有很高的识别率,这样便提高了该弱分类算法的识别率。在产生单个的基分类器时可用相同的分类算法,也可用不同的分类算法,这些算法一般是不稳定的弱分类算法,如神经网络(BP) ,决策树(C4.5)等。

**Adaboosting**

Adaboost是一种基于boost思想的一种自适应的迭代式算法，其核心思想是针对同一个训练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。
Adaboost算法本身是通过改变数据权值分布来实现的，它根据每次训练集中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据送给下层分类器进行训练，最后将每次得到的分类器最后融合起来，作为最后的决策分类器。
关于弱分离器的组合，Adaboost算法采用加权多数表决的方法。具体来说，就是加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率较大的弱分类器的权值，使其在表决中起较小的作用。‘

**流程** 1. 给训练数据集中的每一个样本赋予权重，权重初始化相等值，这些权重形成向量D。一般初始化所有训练样例的权重为1/N,其中N是样例数。
2. 在训练集上训练出弱分类器并计算该分类器的错误率。
3. 同一数据集上再次训练分类器，调整样本的权重，将第一次分对的样本权重降低，第一次分错的样本权重提高。
4. 最后给每一个分类器分配一个权重值alpha,alpha = 0.5 * ln((1-错误率)/错误率)
5. 计算出alpha值后，可以对权重向量D进行更新，以使得正确分类的样本权重降低而错分样本的权重升高。

**优点** 1. Adaboost是一种有很高精度的分类器；
2. 可以使用各种方法构建子分类器，Adaboost算法提供的是框架；
3. 当使用简单分类器时，计算出的结果可以理解的，而弱分类器构造及其简单；
4. 简单，不用做特征筛选；
5. 不用担心overfitting(过拟合）问题

**GBDT**
GBDT(Gradient Boosting Decision Tree)又叫MART(Multiple Additive Regression Tree),是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。
GBDT主要由三个概念组成:1.Regression Decision Tree(及DT回归决策树) 2. Gradient Boosting(即GB); 3. Shrinkage(算法的一个重要演进分枝)
**Regression Decision Tree** 回归树总体流程也是类似，不过在每个节点（不一定是叶子结点）都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差--即（每个人的年龄 - 预测年龄）^2 的总和 / N，或者说每个人的预测误差平方和 除以 N。**Boosting**,迭代，即通过迭代多棵树来共同决策。
GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子结点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义。

[GBDT和AdaBoost](https://zhuanlan.zhihu.com/p/40096769)

## 1.5.2 Bagging

[Bagging和Boosting](https://www.cnblogs.com/earendil/p/8872001.html)
从原始样本集中使用Bootstraping方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集。（k个训练集之间相互独立，元素可以有重复）
对于k个训练集，我们训练k个模型（这k个模型可以根据具体问题而定，比如决策树，knn等）
对于分类问题：由投票表决产生分类结果；对于回归问题：由k个模型预测结果的均值作为最后预测结果。（所有模型的重要性相同）

## 1.5.3 Stacking

[传送门](https://baijiahao.baidu.com/s?id=1633580172255481867&wfr=spider&for=pc)
Stacking 与 bagging 和 boosting 主要存在两方面的差异。首先，Stacking 通常考虑的是异质弱学习器（不同的学习算法被组合在一起），而bagging 和 boosting 主要考虑的是同质弱学习器。其次，stacking 学习用元模型组合基础模型，而bagging 和 boosting 则根据确定性算法组合弱学习器。
正如上文已经提到的，stacking 的概念是学习几个不同的弱学习器，并通过训练一个元模型来组合它们，然后基于这些弱模型返回的多个预测结果输出最终的预测结果。因此，为了构建 stacking 模型，我们需要定义两个东西：想要拟合的 L 个学习器以及组合它们的元模型。
例如，对于分类问题来说，我们可以选择 KNN 分类器、logistic 回归和SVM 作为弱学习器，并决定学习神经网络作为元模型。然后，神经网络将会把三个弱学习器的输出作为输入，并返回基于该输入的最终预测。

# 2. 无监督学习
降维（PCA，流形学习mainfold），聚类（k-means，meanshift，谱聚类，EM算法等）

## 2.1 降维
**PCA** 
[传送门](https://www.zhihu.com/question/41120789?sort=created)

线性变换将向量投影到低维空间。对向量进行投影就是让向量左乘一个矩阵得到结果向量，这也是线性代数中讲述的线性变换：$y=Wx$。降维要确保的是在低维空间中的投影能很好的近似表达原始向量，即重构误差最小化。

## 2.2 聚类
**k-means**
[传送门](https://zhuanlan.zhihu.com/p/42486145)

在k-means算法中，用质心来表示cluster；且容易证明k-means算法收敛等同于所有质心不再发生变化。基本的k-means算法流程如下：
选取k个初始质心（作为初始cluster）；
repeat：
    对每个样本点，计算得到距其最近的质心，将其类别标为该质心所对应的cluster；
    重新计算k个cluser对应的质心；
until 质心不再发生变化

k-means存在缺点：
1. k-means是局部最优的，容易受到初始质心的影响；比如在下图中，因选择初始质心不恰当而造成次优的聚类结果（SSE较大）。
2. k值的选取也会直接影响聚类结果，最优聚类的k值应与样本数据本身的结构信息相吻合，而这种结构信息是很难去掌握，因此选取最优k值是非常困难的。

为了解决上述存在缺点，在基本k-means的基础上发展而来二分 (bisecting) k-means，其主要思想：一个大cluster进行分裂后可以得到两个小的cluster；为了得到k个cluster，可进行k-1次分裂。算法流程如下
初始只有一个cluster包含所有样本点；
repeat:
    从待分裂的clusters中选择一个进行二元分裂，所选的cluster应使得SSE最小；
until 有k个cluster

# 强化学习
有模型，无模型，蒙特卡罗树搜索

1


1
1

1


1

